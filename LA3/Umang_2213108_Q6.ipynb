{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "class Conv_op:\n",
    "\n",
    "  def __init__(self, num_filters, filter_size):\n",
    "    self.num_filters = num_filters\n",
    "    self.filter_size = filter_size\n",
    "    self.conv_filter = np.random.randn(num_filters, filter_size, filter_size)/(filter_size * filter_size)\n",
    "\n",
    "  def image_region(self, image):\n",
    "     height, width = image.shape\n",
    "     self.image = image\n",
    "     for j in range(height - self.filter_size + 1):\n",
    "       for k in range(width - self.filter_size + 1):\n",
    "         image_patch = image[ j : (j+ self.filter_size), k : (k + self.filter_size)]\n",
    "         yield image_patch, j, k\n",
    "\n",
    "  def forward_prop(self, image):\n",
    "    height, width = image.shape\n",
    "    conv_out = np.zeros( (height - self.filter_size +1, width - self.filter_size +1, self.num_filters))\n",
    "    for image_patch, i, j in self.image_region(image):\n",
    "      conv_out[i,j] = np.sum(image_patch*self.conv_filter, axis = (1,2))\n",
    "    return conv_out\n",
    "    \n",
    "#building a backward propagation layer\n",
    "  def back_prop(self, dL_dout, learning_rate):\n",
    "    dL_dF_params = np.zeros(self.conv_filter.shape)\n",
    "    for image_patch, i, j in self.image_region(self.image):\n",
    "      for k in range(self.num_filters):\n",
    "        dL_dF_params[k] += image_patch*dL_dout[i,j,k]\n",
    "\n",
    "    #filter params update\n",
    "    self.conv_filter -= learning_rate*dL_dF_params\n",
    "    return dL_dF_params\n",
    "\n",
    "\n",
    "#building a maxpool layer\n",
    "class Max_Pool:\n",
    "  def __init__(self, filter_size):\n",
    "    self.filter_size = filter_size\n",
    "  \n",
    "  def image_region(self, image):\n",
    "    new_height = image.shape[0]//self.filter_size\n",
    "    new_width = image.shape[1]//self.filter_size\n",
    "    self.image = image\n",
    "    for i in range(new_height):\n",
    "      for j in range(new_width):\n",
    "        image_patch = image[ (i*self.filter_size) : (i*self.filter_size + self.filter_size), (j*self.filter_size) : (j*self.filter_size + self.filter_size)  ]\n",
    "        yield image_patch, i, j\n",
    "\n",
    "  def forward_prop(self, image):\n",
    "    height, width, num_filters = image.shape\n",
    "    output = np.zeros( (height//self.filter_size, width//self.filter_size, num_filters))\n",
    "    for image_patch, i, j in self.image_region(image):\n",
    "      output[i,j] = np.amax(image_patch, axis = (0,1))\n",
    "    return output\n",
    "\n",
    "  def back_prop(self, dL_dout):\n",
    "    dL_dmax_pool = np.zeros(self.image.shape)\n",
    "    for image_patch, i, j in self.image_region(self.image):\n",
    "      height, width, num_filters = image_patch.shape\n",
    "      maximum_val = np.amax(image_patch, axis = (0,1))\n",
    "\n",
    "      for il in range(height):\n",
    "        for jl in range(width):\n",
    "          for kl in range(num_filters):\n",
    "            if image_patch[il, jl, kl] == maximum_val[kl]:\n",
    "              dL_dmax_pool[i*self.filter_size + il, j*self.filter_size + jl, kl] = dL_dout[i,j,kl]\n",
    "      return dL_dmax_pool\n",
    "    \n",
    "    \n",
    "#building a softmax layer\n",
    "class Softmax:\n",
    "  def __init__(self, input_node, softmax_node ):\n",
    "    self.weight = np.random.randn(input_node, softmax_node)/input_node\n",
    "    self.bias = np.zeros(softmax_node)\n",
    "\n",
    "  def forward_prop(self, image):\n",
    "    self.orig_im_shape = image.shape\n",
    "    image_modified = image.flatten()\n",
    "    self.modified_input = image_modified\n",
    "    output_val = np.dot(image_modified, self.weight) + self.bias\n",
    "    self.out = output_val\n",
    "    exp_out = np.exp(output_val)\n",
    "    return exp_out/np.sum(exp_out, axis = 0)\n",
    "\n",
    " #building a backprop layer\n",
    "  def back_prop(self, dL_out, learning_rate):\n",
    "    for i, grad in enumerate(dL_out):\n",
    "      if grad == 0:\n",
    "        continue\n",
    "    \n",
    "    transformation_eq = np.exp(self.out)\n",
    "    S_total = np.sum(transformation_eq)\n",
    "\n",
    "    #gradients w.r.t out(z)\n",
    "    dy_dz = -transformation_eq[i]*transformation_eq/(S_total**2)\n",
    "    dy_dz[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "    #gradients of totals against weights/biases/input\n",
    "    dz_dw = self.modified_input\n",
    "    dz_db = 1\n",
    "    dz_d_inp = self.weight\n",
    "\n",
    "    #gradients of loss against totals\n",
    "    dL_dz = grad*dy_dz\n",
    "\n",
    "    #gradients of loss against weights/biases/inputs\n",
    "    dL_dw = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
    "    dL_db = dL_dz * dz_db\n",
    "    dL_d_inp = dz_d_inp @ dL_dz\n",
    "\n",
    "    #update weights and biases\n",
    "    self.weight -= learning_rate*dL_dw\n",
    "    self.bias -= learning_rate*dL_db\n",
    "\n",
    "    return dL_d_inp.reshape(self.orig_im_shape) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_trian, y_train), (X_test, y_test)=mnist.load_data()\n",
    "train_images=X_trian[:1500]\n",
    "train_labels=y_train[:1500]\n",
    "test_images=X_test[:1500]\n",
    "test_labels=y_test[:1500]\n",
    "\n",
    "conv=Conv_op(8,3)   #28*28*1-->26*26*8\n",
    "pool=Max_Pool(2)    #26*26*8-->13*13*8\n",
    "softmax=Softmax(13*13*8, 10)  #13*13*8-->10\n",
    "\n",
    "def cnn_forward_prop(image, label):\n",
    "    out_p=conv.forward_prop((image/255)-0.5)\n",
    "    out_p=pool.forward_prop(out_p)\n",
    "    out_p=softmax.forward_prop(out_p)\n",
    "    \n",
    "    cross_ent_loss=-np.log(out_p[label])\n",
    "    accuracy_eval=1 if np.argmax(out_p)==label else 0\n",
    "    return out_p, cross_ent_loss, accuracy_eval\n",
    "\n",
    "def training_cnn(image, label, learn_rate=0.005):\n",
    "    out, loss, acc=cnn_forward_prop(image, label)\n",
    "    \n",
    "    gradient=np.zeros(10)\n",
    "    gradient[label]=-1/out[label]\n",
    "    \n",
    "    grad_back=softmax.back_prop(gradient, learn_rate)\n",
    "    grad_back=pool.back_prop(grad_back)\n",
    "    grad_back=conv.back_prop(grad_back, learn_rate)\n",
    "    \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Testing Phase\n",
      "Test Loss:  8.408029089684007\n",
      "Test Accuracy:  0.096\n"
     ]
    }
   ],
   "source": [
    "for epoch1 in range(4):\n",
    "    #print(\"Epoch\", epoch1)\n",
    "    shuffle_data=np.random.permutation(len(train_images))\n",
    "    train_images=train_images[shuffle_data]\n",
    "    train_labels=train_labels[shuffle_data]   \n",
    "    loss=0\n",
    "    num_correct=0\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i % 100==0:\n",
    "            #print(\"%d steps. Avg loss: %.3f. and Accuracy: %d%%\"%(i+1, loss/100, num_correct))\n",
    "            loss=0\n",
    "            num_correct=0\n",
    "        l1, accu=training_cnn(im, label)\n",
    "        loss+=l1\n",
    "        num_correct+=accu\n",
    "        \n",
    "        \n",
    "print(\"**Testing Phase\")\n",
    "loss=0\n",
    "num_correct=0\n",
    "\n",
    "for im, label in zip(test_images, test_labels):\n",
    "    _, l1, accu=cnn_forward_prop(im, label)\n",
    "    loss+=l1\n",
    "    num_correct+=accu\n",
    "    \n",
    "num_tests=len(test_images)\n",
    "print(\"Test Loss: \", loss/num_tests)\n",
    "print(\"Test Accuracy: \", num_correct/num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ddfe56edc95f73912f77c58ed75f9b5f3722acd7cbc9160fd4007e7af55801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvolutionalLayer:\n",
    "    def __init__(self, n_input_channels, m_output_channels, kernel_size, stride, padding):\n",
    "        self.n_input_channels = n_input_channels\n",
    "        self.m_output_channels = m_output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weights = np.random.randn(m_output_channels, n_input_channels, kernel_size, kernel_size)\n",
    "        self.biases = np.zeros((m_output_channels, 1))\n",
    "        self.output = None\n",
    "        self.input = None\n",
    "        self.d_weights = np.zeros(self.weights.shape)\n",
    "        self.d_biases = np.zeros(self.biases.shape)\n",
    "        \n",
    "    def conv_forward(self, input_data):\n",
    "        n, c, h, w = input_data.shape\n",
    "        out_h = (h - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        out_w = (w - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        padded_input = np.pad(input_data, ((0,0), (0,0), (self.padding, self.padding), (self.padding, self.padding)), 'constant')\n",
    "        self.output = np.zeros((n, self.m_output_channels, out_h, out_w))\n",
    "        self.input = input_data\n",
    "        for i in range(n):\n",
    "            for j in range(self.m_output_channels):\n",
    "                for k in range(out_h):\n",
    "                    for l in range(out_w):\n",
    "                        self.output[i, j, k, l] = np.sum(padded_input[i, :, k * self.stride:k * self.stride + self.kernel_size, l * self.stride:l * self.stride + self.kernel_size] * self.weights[j, :, :, :]) + self.biases[j]\n",
    "        return self.output\n",
    "    \n",
    "    def conv_backward(self, d_output):\n",
    "        n, c, h, w = self.input.shape\n",
    "        d_input = np.zeros(self.input.shape)\n",
    "        padded_d_input = np.pad(d_input, ((0,0), (0,0), (self.padding, self.padding), (self.padding, self.padding)), 'constant')\n",
    "        for i in range(n):\n",
    "            for j in range(self.m_output_channels):\n",
    "                for k in range(h):\n",
    "                    for l in range(w):\n",
    "                        padded_d_input[i, :, k:k + self.kernel_size, l:l + self.kernel_size] += self.weights[j, :, :, :] * d_output[i, j, k // self.stride,l // self.stride]\n",
    "                        \n",
    "        self.d_weights = np.zeros(self.weights.shape)\n",
    "        self.d_biases = np.zeros(self.biases.shape)\n",
    "        for i in range(n):\n",
    "            for j in range(self.m_output_channels):\n",
    "                for k in range(self.kernel_size):\n",
    "                    for l in range(self.kernel_size):\n",
    "                        self.d_weights[j, :, k, l] = np.sum(self.input[i, :, k:k + h, l:l + w] * d_output[i, j, :, :], axis=(0, 1))\n",
    "        self.d_biases = np.sum(d_output, axis=(0, 2, 3))\n",
    "        padded_d_input = padded_d_input[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
    "        return d_input\n",
    "    \n",
    "    \n",
    "    def conv_flatten(self, input):\n",
    "        n, c, h, w = input.shape\n",
    "        output = input.reshape(n, c * h * w)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 1, 28, 28)\n",
      "Output Shape: (1, 10, 28, 28)\n",
      "Flattened Shape:  (1, 7840)\n"
     ]
    }
   ],
   "source": [
    "# Defining the input image shape\n",
    "\n",
    "# n = number of images in the tensor.\n",
    "\n",
    "# c = number of channels in each image ( grayscale image has 1 channel, RGB image has 3 channels (red, green, and blue))\n",
    "\n",
    "# h = height of each image.\n",
    "\n",
    "# w = width of each image.\n",
    "\n",
    "n, c, h, w = 1, 1, 28, 28\n",
    "\n",
    "# Defining the convolutional layer with kernel size 3, stride 1 and padding 1\n",
    "conv_layer = ConvolutionalLayer(n_input_channels=1, m_output_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Defining the input image\n",
    "input_image = np.random.randn(n, c, h, w)\n",
    "\n",
    "# Printing the shape of the input\n",
    "print(\"Input Shape:\", input_image.shape)\n",
    "\n",
    "# Passing the input image through the convolutional layer\n",
    "output = conv_layer.conv_forward(input_image)\n",
    "\n",
    "# Printing the shape of the output\n",
    "print(\"Output Shape:\", output.shape)\n",
    "\n",
    "# Flattening the convolved image\n",
    "flattened_output = conv_layer.conv_flatten(output)\n",
    "print(\"Flattened Shape: \", flattened_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ddfe56edc95f73912f77c58ed75f9b5f3722acd7cbc9160fd4007e7af55801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
